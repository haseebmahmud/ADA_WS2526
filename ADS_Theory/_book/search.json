[
  {
    "objectID": "chapter_6.html",
    "href": "chapter_6.html",
    "title": "6  Sampling design",
    "section": "",
    "text": "6.1 Probability sampling\nProbability sampling (or representative sampling) is most commonly associated with survey-based research strategies where you need to make inferences from your sample about a population to answer your research question(s) or to meet your objectives. The process of probability sampling can be divided into four stages:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sampling design</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#probability-sampling",
    "href": "chapter_6.html#probability-sampling",
    "title": "6  Sampling design",
    "section": "",
    "text": "Identify a suitable sampling frame based on your research question(s) or objectives.\nDecide on a suitable sample size.\nSelect the most appropriate sampling technique and select the sample.\nCheck that the sample is representative of the population.\n\n\n6.1.1 The sampling frame\nThe sampling frame for any probability sample is a complete list of all the cases in the population from which your sample will be drawn. If your research question or objective is concerned with members of a local golf club, your sampling frame will be the complete membership list for that golf club. If your research question or objective is concerned with registered childminders in a local area, your sampling frame will be the directory of all registered childminders in this area. In setting sample frame, the following questions should be answered:\n\nHow recently was the sampling frame compiled, in particular is it up to date?\nDoes the sampling frame include all cases, in other words is it complete?\nDoes the sampling frame contain the correct information, in other words is it accurate?\nDoes the sampling frame exclude irrelevant cases, in other words is it precise?\n(For purchased lists) Can you establish and control precisely how the sample will be selected?\n\n\n\n6.1.2 Deciding on a suitable sample size\nGeneralisations about populations from data collected using any probability sample are based on statistical probability. The larger your sample’s size the lower the likely error in generalising to the population. Probability sampling is therefore a compromise between the accuracy of your findings and the amount of time and money you invest in collecting, checking and analysing the data. Your choice of sample size within this compromise is governed by:\n\nthe confidence you need to have in your data – that is, the level of certainty that the characteristics of the data collected will represent the characteristics of the total population;\nthe margin of error that you can tolerate - that is, the accuracy you require for any esti- mates made from your sample;\nthe types of analyses you are going to undertake; and to a lesser extent:\nthe size of the total population from which your sample is being drawn.\n\nStatisticians have proved that the larger the absolute size of a sample, the more closely its distribution will be to the normal distribution and thus the more robust it will be. This relationship, known as the central limit theorem, occurs even if the population from which the sample is drawn is not normally distributed. Statisticians have also shown that a sample size of 30 or more will usually result in a sampling distribution for the mean that is very close to a normal distribution.\nIt is likely that, if you are undertaking statistical analyses on your sample, you will be drawing conclusions from these analyses about the population from which your sample was selected. This process of coming up with conclusions about a population on the basis of data describing the sample is called statistical inference and allows you to calculate how probable it is that your result, given your sample size, could have been obtained by chance. Such probabilities are usually calculated automatically by statistical analysis software. However, it is worth remembering that, providing they are not biased, samples of larger absolute size are more likely to be representative of the population from which they are drawn than smaller samples and, in particular, the mean (average) calculated for the sample is more likely to equal the mean for the population. This is known as the law of large numbers.\nResearchers normally work to a 95 per cent level of certainty. This means that if your sample was selected 100 times, at least 95 of these samples would be certain to represent the characteristics of the population. The confidence level states the precision of your estimates of the population as the percentage that is within a certain range or margin of error.\n\n\n\n\n\n\nFigure 6.2: Sample sizes for different sizes of population at a 95 percent confidence level (assuming the data are collected from all cases in the sample)\n\n\n\nThe above table provides a rough guide to the different minimum sample sizes required from different sizes of population given a 95 per cent confidence level for different margins of error. It assumes that data are collected from all cases in the sample. For most business and management research, researchers are content to estimate the population’s characteristics at 95 per cent certainty to within plus or minus 3 to 5 per cent of its true values. This means that if 45 per cent of your sample are in a certain category then you will be 95 per cent certain that your estimate for the total population within the same category will be 45 per cent plus or minus the margin of error – somewhere between 42 and 48 per cent for a 3 per cent margin of error.\nAs you can see from the above, the smaller the absolute size of the sample and, to a far lesser extent, the smaller the relative proportion of the total population sampled, the greater the margin of error. Within this, the impact of absolute sample size on the margin of error decreases for larger sample sizes. Some argue that it is for this reason that many market research companies limit their samples’ sizes to approximately 2000. Unfortunately, from many samples, a 100 per cent response rate is unlikely and so your sample will need to be larger to ensure sufficient responses for the margin of error you require.\n\n\n6.1.3 Selecting the most appropriate sampling techniques and the sample\nHaving chosen a suitable sampling frame and established the actual sample size required, you need to select the most appropriate sampling technique to obtain a representative sample. Five main techniques can be used to select a probability sample: - simple random; - systematic; - stratified random; - cluster; - multi-stage.\nYour choice of probability sampling technique depends on your research question(s) and your objectives.\n\n\n\n\n\n\nFigure 6.3: Selecting a probability sample)\n\n\n\n\n6.1.3.1 Simple random sampling\nSimple random sampling (sometimes called just random sampling) involves you selecting the sample at random from the sampling frame using either random number tables.\nIt is usual to select your first random number at random (closing your eyes and pointing with your finger is one way!) as this ensures that the set of random numbers obtained for different samples is unlikely to be the same. If you do not, you will obtain sets of numbers that are random but identical.\n\n\n6.1.3.2 Systematic sampling\nSystematic sampling involves you selecting the sample at regular intervals from the sampling frame. To do this you:\n\nNumber each of the cases in your sampling frame with a unique number. The first case is numbered 0, the second 1 and so on.\nSelect the first case using a random number.\nCalculate the sampling fraction.\nSelect subsequent cases systematically using the sampling fraction to determine the frequency of selection.\n\n\n\n6.1.3.3 Stratified random sampling\nStratified random sampling is a modification of random sampling in which you divide the population into two or more relevant and significant strata based on one or a number of attributes. In effect, your sampling frame is divided into a number of subsets. A ran- dom sample (simple or systematic) is then drawn from each of the strata. Consequently, stratified sampling shares many of the advantages and disadvantages of simple random or systematic sampling. Dividing the population into a series of relevant strata means that the sample is more likely to be representative, as you can ensure that each of the strata is represented proportionally within your sample. However, it is only possible to do this if you are aware of, and can easily distinguish, significant strata in your sampling frame. In addition, the extra stage in the sampling procedure means that it is likely to take longer, to be more expensive, and to be more difficult to explain than simple random or systematic sampling.\nIn some instances, your sampling frame will already be divided into strata. A sampling frame of employee names that is in alphabetical order will automatically ensure that, if systematic sampling is used (discussed earlier), employees will be sampled in the correct proportion to the letter with which their name begins. Similarly, membership lists that are ordered by date of joining will automatically result in stratification by length of membership if systematic sampling is used.\n\n\n\n\n\n\nFigure 6.4: Comparison of different techniques)\n\n\n\n\n\n6.1.3.4 Cluster sample\nCluster sampling is, on the surface, similar to stratified sampling as you need to divide the population into discrete groups prior to sampling (Henry 1990). The groups are termed clusters in this form of sampling and can be based on any naturally occurring grouping. For example, you could group your data by type of manufacturing firm or geographical area.\nFor cluster sampling your sampling frame is the complete list of clusters rather than a complete list of individual cases within the population. You then select a few clusters, normally using simple random sampling. Data are then collected from every case within the selected clusters. The technique has three main stages:\n\nchoose the cluster grouping for your sampling frame.\nNumber each of the clusters with a unique number. The first cluster is numbered 0, the second 1 and so on.\nSelect your sample using some form of random sampling as discussed earlier.\n\nSelecting clusters randomly makes cluster sampling a probability sampling technique.\n\n\n6.1.3.5 Multi-stage sampling\nMulti-stage sampling, sometimes called multi-stage cluster sampling, is a development of cluster sampling. It is normally used to overcome problems associated with a geographically dispersed population when face-to-face contact is needed or where it is expensive and time consuming to construct a sampling frame for a large geographical area. However, like cluster sampling, you can use it for any discrete groups, including those that are not geographically based. The technique involves taking a series of cluster samples, each involving some form of random sampling.\n\n\n\n\n\n\nFigure 6.5: Phases of multistage sampling)\n\n\n\n\n\n\n6.1.4 Checking that the sample is representative\nOften it is possible to compare data you collect from your sample with data from another source for the population. For example, you can compare data on the age and socio-economic characteristics of respondents in a marketing survey with these characteristics for the population in that country as recorded by the latest national census of population. If there is no statistically significant difference, then the sample is representative with respect to these characteristics.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sampling design</span>"
    ]
  },
  {
    "objectID": "chapter_6.html#non-probability-sampling",
    "href": "chapter_6.html#non-probability-sampling",
    "title": "6  Sampling design",
    "section": "6.2 Non-probability sampling",
    "text": "6.2 Non-probability sampling\nThe techniques for selecting samples discussed earlier have all been based on the assumption that your sample will be chosen statistically at random. Consequently, it is possible to specify the probability that any case will be included in the sample. However, within business research, such as market surveys and case study research, this may either not be possible (as you do not have a sampling frame) or appropriate to answering your research question. This means your sample must be selected some other way. Non- probability sampling (or non-random sampling) provides a range of alternative techniques to select samples based on your subjective judgement. In the exploratory stages of some research projects, such as a pilot survey, a non-probability sample may be the most practical, although it will not allow the extent of the problem to be determined. Subsequent to this, probability sampling techniques may be used. For other business and management research projects your research question(s), objectives and choice of research strategy may dictate non-probability sampling.\n\n6.2.1 Deciding on a suitatble sample size\nFor all non-probability sampling techniques, other than for quota samples the issue of sample size is ambiguous and, unlike probability sampling, there are no rules. Rather the logical relationship between your sample selection technique and the purpose and focus of your research is important, generalisations being made to theory rather than about a population. Consequently, your sample size is dependent on your research question(s) and objectives - in particular, what you need to find out, what will be useful, what will have credibility and what can be done within your available resources.\n\n\n\n\n\n\nFigure 6.6: Selecting a non-probability sampling technique)\n\n\n\n\n\n6.2.2 Selecting the most appropriate sampling technique and the sample\nHaving decided the likely suitable sample size, you need to select the most appropriate sampling technique to enable you to answer your research question from the range of non-probability sampling techniques available.\n\n6.2.2.1 Quota sampling\nQuota sampling is entirely non-random and is normally used for interview surveys. It is based on the premise that your sample will represent the population as the variability in your sample for various quota variables is the same as that in the population. Quota sampling is therefore a type of stratified sample in which selection of cases within strata is entirely non-random (Barnett 1991). To select a quota sample you:\n\nDivide the population into specific groups.\nCalculate a quota for each group based on relevant and available data.\nGive each interviewer an ‘assignment’, which states the number of cases in each quota from which they must collect data.\nCombine the data collected by interviewers to provide the full sample.\n\nQuota sampling has a number of advantages over the probabilistic techniques. In particular, it is less costly and can be set up very quickly. If, as with television audience research surveys, your data collection needs to be undertaken very quickly then quota sampling may be the only possibility. In addition, it does not require a sampling frame and, therefore, may be the only technique you can use if one is not available.\nQuota sampling is normally used for large populations. For small populations, it is usually possible to obtain a sampling frame. Decisions on sample size are governed by the need to have sufficient responses in each quota to enable subsequent statistical analy- ses to be undertaken. This often necessitates a sample size of between 2000 and 5000.\n\n\n6.2.2.2 Purposive sampling\nPurposive or judgemental sampling enables you to use your judgement to select cases that will best enable you to answer your research question(s) and to meet your objectives. This form of sample is often used when working with very small samples such as in case study research and when you wish to select cases that are particularly informative.\n\n\n6.2.2.3 Snowball sampling\nSnowball sampling is commonly used when it is difficult to identify members of the desired population, for example people who are working while claiming unemployment benefit. You, therefore, need to:\n\nMake contact with one or two cases in the population.\nAsk these cases to identify further cases.\nAsk these new cases to identify further new cases (and so on).\nStop when either no new cases are given or the sample is as large as is manageable.\n\nThe main problem is making initial contact. Once you have done this, these cases identify further members of the population, who then identify further members, and so the sample snowballs.\n\n\n\n\n\n\nFigure 6.7: Impack of various factors on choice of non-probability sampling techniques)\n\n\n\n\n\n6.2.2.4 Self-selection sampling\nSelf-selection sampling occurs when you allow each case, usually individuals, to identify their desire to take part in the research. You therefore:\n\nPublicise your need for cases, either by advertising through appropriate media or by asking them to take part.\nCollect data from those who respond.\n\nPublicity for convenience samples can take many forms. These include articles and advertisements in magazines that the population are likely to read, postings on appropriate Internet newsgroups and discussion groups, hyperlinks from other websites as well as letters or emails of invitation to colleagues and friends (Box 7.14). Cases that self-select often do so because of their feelings or opinions about the research question(s) or stated objectives.\n\n\n6.2.2.5 Convenience sampling\nConvenience sampling (or haphazard sampling) involves selecting haphazardly those cases that are easiest to obtain for your sample, such as the person interviewed at random in a shopping centre for a television programme or the book about entrepreneurship you find at the airport. The sample selection process is continued until your required sample size has been reached.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sampling design</span>"
    ]
  },
  {
    "objectID": "chapter_1.html",
    "href": "chapter_1.html",
    "title": "1  What is research",
    "section": "",
    "text": "1.1 Research method vs. research methodology\nA research method is a way of conducting and implementing research. The term ‘methods’ refers to specific activities (e.g. designing questionnaire, conducting interviews, focus groups, observation etc.). On the other hand, research methodology is the science and philosophy behind all research. It is more about our attitude to and our understanding of research and the strategy or approach you choose to answer research questions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is research</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#research-method-vs.-research-methodology",
    "href": "chapter_1.html#research-method-vs.-research-methodology",
    "title": "1  What is research",
    "section": "1.1 Research method vs. research methodology",
    "text": "1.1 Research method vs. research methodology\nA research method is a way of conducting and implementing research. The term ‘methods’ refers to specific activities (e.g. designing questionnaire, conducting interviews, focus groups, observation etc.). On the other hand, research methodology is the science and philosophy behind all research. It is more about our attitude to and our understanding of research and the strategy or approach you choose to answer research questions."
  },
  {
    "objectID": "chapter_1.html#why-is-research-conducted",
    "href": "chapter_1.html#why-is-research-conducted",
    "title": "1  What is research",
    "section": "1.2 Why is research conducted",
    "text": "1.2 Why is research conducted\nResearch is conducted for a number of reasons, which in turn depend on the objectives of any particular ‘research problem’. It may be to find out something we do not already know or to enhance our understanding of phenomena that we already know something about. In the business arena, however, research tends to be undertaken in order to achieve one or more of the following objectives (Adams, Khan, and Raeside 2014):\n\nTo gain a competitive advantage\nTo test new products and services\nTo solve a management/organisational problem\nTo provide information, which may help to avoid future business problems\nTo forecast future sales\nTo better understand shifts in consumer attitudes and tastes\nTo enhance profitability\nTo reduce operational costs\nTo enable the management to priorities strategic options for the future etc.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is research</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#approaches-to-business-and-social-research",
    "href": "chapter_1.html#approaches-to-business-and-social-research",
    "title": "1  What is research",
    "section": "1.3 Approaches to business and social research",
    "text": "1.3 Approaches to business and social research\nResearchers usually handle numerous problems and apply research methods to obtain the best guess answers to their questions. They may use a single study or a combination of two designs. The investigator has to decide about the types and combinations of research forms that best serve the goals of the study. Broadly speaking, there are two main domains of research frequently observed in the literature, which are Quantitative research and Qualitative research. It is possible to combine quantitative and qualitative together to answer a single research question. Those approaches are known as mixed method research works. The diverse practices and uses of today’s research practices are listed in the following paragraphs.\n\nQuantitative research\nQualitative research\nPure theoretical research\nApplied research\nLongitudinal studies\nTheory vs. empirical study",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is research</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#the-research-process",
    "href": "chapter_1.html#the-research-process",
    "title": "1  What is research",
    "section": "1.4 The research process",
    "text": "1.4 The research process\n\n\n\n\n\n\nFigure 1.1: The Research process (Saunders, Lewis, and Thornhill (2019))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is research</span>"
    ]
  },
  {
    "objectID": "chapter_1.html#the-hallmarks-of-scientific-research",
    "href": "chapter_1.html#the-hallmarks-of-scientific-research",
    "title": "1  What is research",
    "section": "1.5 The hallmarks of scientific research",
    "text": "1.5 The hallmarks of scientific research\nThe hallmarks or main distinguishing characteristics of scientific research may be listed as follows (Bougie and Sekaran (2020)):\n\nPurposiveness\nRigor\nTestability\nReplicability\nPrecision and confidence\nObjectivity\nGeneralizability\nParsimony\n\n\n\n\n\nAdams, John, Hafiz T. A. Khan, and R. Raeside. 2014. Research Methods for Business and Social Science Students. Second edition. Los Angeles: SAGE.\n\n\nBougie, Roger, and Uma Sekaran. 2020. Research Methods for Business: A Skill-Building Approach. Eight edition. Hoboken, NJ: Wiley.\n\n\nGhauri, Pervez N., and Kjell Grønhaug. 2002. Research Methods in Business Studies: A Practical Guide. 2nd ed. Harlow, England ; New York: Financial Times Prentice Hall.\n\n\nSaunders, M. N. K., Philip Lewis, and Adrian Thornhill. 2019. Research Methods for Business Students. Eighth Edition. New York: Pearson.\n\n\nWalliman, Nicholas. 2005. Your Research Project: A Step-by-Step Guide for the First-Time Researcher. 2nd ed. London ; Thousand Oaks, Calif: Sage Publications.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is research</span>"
    ]
  },
  {
    "objectID": "chapter_2.html",
    "href": "chapter_2.html",
    "title": "2  Formulating and clarifying the research topic",
    "section": "",
    "text": "2.1 Attributes of a good research topic\nCapability: is it feasible?\nAppropriateness: is it worthwhile?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Formulating and clarifying the research topic</span>"
    ]
  },
  {
    "objectID": "chapter_2.html#generating-and-refining-research-ideas",
    "href": "chapter_2.html#generating-and-refining-research-ideas",
    "title": "2  Formulating and clarifying the research topic",
    "section": "2.2 Generating and refining research ideas",
    "text": "2.2 Generating and refining research ideas\n\n2.2.1 Generating ideas\nIf you have not been given an initial research idea there is a range of techniques that can be used to find and select a topic that you would like to research. They can be thought of as those that are predominantly rational thinking and those that involve more creative thinking.\n\n\n\nTable 2.1: More frequently used techniques for generating and refining research ideas\n\n\n\n\n\n\n\n\n\nRational thinking\nCreative thinking\n\n\n\n\nExamining your own strenths and interests\nKeeping a notebook of ideas\n\n\nLooking at past project titles\nExploring personal preferences using past projects\n\n\nDiscussion\nRelevance trees/mindmap\n\n\nSearching the literature\nBrainstorming\n\n\nScanning the media\n\n\n\n\n\n\n\n\n\n2.2.2 Refining research ideas\nThe Delphi technique\nAn additional approach that our students have found particularly useful in refining their research ideas is the Delphi technique. This involves using a group of people who are either involved or interested in the research idea to generate and choose a more specific research idea (Robson and McCartan (2016)). To use this technique you need:\n\nto brief the members of the group about the research idea (they can make notes if they wish);\nat the end of the briefing to encourage group members to seek clarification and more information as appropriate;\nto ask each member of the group, including the originator of the research idea, to generate independently up to three specific research ideas based on the idea that has been described (they can also be asked to provide a justification for their specific ideas);\nto collect the research ideas in an unedited and non-attributable form and to distribute them to all members of the group;\na second cycle of the process (steps 2 to 4) in which individuals comment on the research ideas and revise their own contributions in the light of what others have said;\n\nThe preliminary study To begin with, it is a good practice to do a prelimanry study to see if the idea/project is viable at all. It is often known as pilot study or proof-of-concept study. It is important to remember that a successful preliminry/pilot/study is not a guarantee for success. The result must be scalable to larger volume.\nOperational definition\nTo formulate a research question, one must define the concepts involved very clearly. Consider this example, “An investigation on mobile entertainment pattern of youth adolescents in Germany”. To begin with this research topic, the researcher must describe the operational definition of:\n\nmobile entertainment: is it watching movies, youtube, listening music only?\nyoung adolescents: what age group we are talking about?\nin Germany: In whole Germany? Or the reseach will take place in a certain part of Germany?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Formulating and clarifying the research topic</span>"
    ]
  },
  {
    "objectID": "chapter_2.html#turning-research-ideas-into-research-projects",
    "href": "chapter_2.html#turning-research-ideas-into-research-projects",
    "title": "2  Formulating and clarifying the research topic",
    "section": "2.3 Turning research ideas into research projects",
    "text": "2.3 Turning research ideas into research projects\n\n2.3.1 Writing research questions\nDefining research questions, rather like generating research ideas, is not a straightforward matter. It is important that the question is sufficiently involved to generate the sort of project that is consistent with the standards expected of you. A question that prompts a descriptive answer, for example ‘What is the proportion of graduates entering the civil service who attended the old, established Germany universities?’, is far easier to answer than: ‘Why are graduates from old, established German universities more likely to enter the civil service than graduates from other universities?’ More will be said about the importance of theory in defining the research question later in this section. However, beware of research questions that are too easy.\nClough and Nutbrown (2012) use what they call the ‘Goldilocks test’ to decide if research questions are either ‘too big’, ‘too small’, ‘too hot’ or ‘just right’. Those that are too big probably need significant research funding because they demand too many resources. Questions that are too small are likely to be of insufficient substance, while those that are too ‘hot’ may be so because of sensitivities that may be aroused as a result of doing the research. This may be because of the timing of the research or the many other reasons that may upset key people who have a role to play, either directly or indirectly, in the research context. Research questions that are ‘just right’, note Clough and Nutbrown (2012), are those that are ‘just right for investigation at this time, by this researcher in this setting’.\nThe pitfall that you must avoid at all costs is asking research questions that will not generate new insights. This raises the question of the extent to which you have consulted the relevant literature. It is perfectly legitimate to replicate research because you have a genuine concern about its applicability to your research setting (for example, your organisation). However, it certainly is not legitimate to display your ignorance of the literature.\nMcNiff and Whitehead (2000) make the point that the research question may not emerge until the research process has started and is therefore part of the process of ‘progressive illumination’. They note that this is particularly likely to be the case in practitioner action research.\n\n\n\nTable 2.2: Examples of research ideas and their derived focus research questions\n\n\n\n\n\n\n\n\n\nResearch idea\nGeneral focus research questions\n\n\n\n\nAdvertisement and share price\nHow does running of a TV advertising campaign designed to boost the image of a company affect its share price?\n\n\nJob recruitment via the internet\nHow effective is recruiting for new staff via the internet in comparison with traditional methods?\n\n\nThe use of aromas as a marketing device\nIn what ways does the use of specific aromas in supermarkets affect buyer behavior?\n\n\nThe use of internet banking\nWhat effect has the growth of Internet banking had upon the uses customers make of branch facilities?\n\n\n\n\n\n\nIt is often a useful starting point in the writing of research questions to begin with one general focus research question that flows from your research idea. This may lead to several more detailed questions or the definition of research objectives. Table 2.2 has some examples of general focus research questions.\nIn order to clarify the research question Clough and Nutbrown (2012) talk of the Russian doll principle. This means taking the research idea and ’breaking down the research questions from the original statement to something which strips away the complication of layers and obscurities until the very essence - the heart - of the question can be expressed … just as the Russian doll is taken apart to reveal a tiny doll at the center Clough and Nutbrown (2012).\n\n\n\nTable 2.3: Phrasing research questions as research objectives\n\n\n\n\n\n\n\n\n\nResearch question\nResearch objective\n\n\n\n\nWhy have organisations introduced team briefing?\nTo identify organisations’ objective for team briefing schemes?\n\n\nHow can the effectiveness of team briefing schemes be measured?\nTo establish suitable effectiveness criteria for team briefing schemes\n\n\nHas team briefing been effective?\nTo describe the extent to which the effectiveness criteria for team briefing have been met\n\n\nHow can the effectiveness of team briefing be explained?\n(a) To determine the factors associated with the effectiveness criteria for team briefing being met (b) To estimate whether some of those factors are more influential that other factors\n\n\nCan the explanation be generalized?\nTo develop an explanatory theory that associates certain factors with the effectiveness of team briefing schemes\n\n\n\n\n\n\nYour research may begin with a general focus research question that then generates more detailed research questions, or you may use your general focus research question as a base from which you write a set of research objectives. Objectives are more generally acceptable to the research community as evidence of the researcher’s clear sense of purpose and direction. It may be that either is satisfactory. Do check whether your examining body has a preference. We contend that research objectives are likely to lead to greater specificity than research or investigative questions. Table 2.3 illustrates this point. It summarizes the objectives of some research conducted by one of our students. Expression of the first research question as an objective prompted a consideration of the objectives of the\nIdeally, the research objective should pass the so-called SMART test. That is the objectives should be:\n_ Specific: What precisely do you hope to achieve from undertaking the research?\n- Measurable: What measures will you use to determine whether you have achieved your objectives?\n- Achievable: Are the targets you have set for yourself achievable given all the possible constraints?\n- Realistic: Given all the other demands upon your time, will you have the time and energy to complete the research on time?\n- Timely: Will you have time to accomplish all your objectives in the time frame you have set?\n\n\n\n\nClough, Peter, and Cathy Nutbrown. 2012. A Student’s Guide to Methodology: Justifying Enquiry. 3rd ed. London: SAGE.\n\n\nMcNiff, Jean, and Jack Whitehead. 2000. Action Research in Organisations. Routledge Studies in Human Resource Development. London ; New York: Routledge.\n\n\nRobson, Colin, and Kieran McCartan. 2016. Real World Research: A Resource for Users of Social Research Methods in Applied Settings. Fourth Edition. Hoboken: Wiley.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Formulating and clarifying the research topic</span>"
    ]
  },
  {
    "objectID": "chapter_3.html",
    "href": "chapter_3.html",
    "title": "3  Literature review",
    "section": "",
    "text": "3.1 A continuous process\nAfter setting up the research question and hypotheses, we need to see what others did in the same subject area. This process is called literature review. There are several objectives of literature review:\nThe literature review can be started while setting up the research question and hypotheses and can continue till the end of the research project. This is because, the research process is often very long and it is important to get updated with publications during ongoing research project. Graphically, it may look like this,",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Literature review</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#purpose-of-critical-review",
    "href": "chapter_3.html#purpose-of-critical-review",
    "title": "3  Literature review",
    "section": "3.2 Purpose of critical review",
    "text": "3.2 Purpose of critical review\nThe precise purpose of your reading of the literature will depend on the approach you are intending to use in your research.\nFor some research projects it is necessary to use the literature to help you to identify theories and ideas that you will test using data. This is known as a deductive approach in which researcher develop a theoretical or conceptual framework, which is to be subsequently tested using data.\nFor other research projects the researcher will be planning to explore the data and to develop theories which will be subsequently related to the literature. This is known as an inductive approach and, although researchers still has a clearly defined purpose with research question(s) and objectives, the researchers do not start with any predetermined theories or conceptual frameworks.\nThe literature review has a number of other purposes. It can be,\n\nto help the researcher to refine the research question(s) and objectives further\nto highlight research possibilities that have been overlooked implicitly in research to date\nto discover explicit recommendations for further research. These can provide you with a superb justification the researchers’ own research question(s) and objectives\nto help the researcher to avoid simply repeating work that has been done already\nto sample current opinions in newspapers, professional and trade journals, thereby gaining insights into the aspects of your research question(s) and objectives that are considered newsworthy;\nto discover and provide an insight into research approaches, strategies and techniques that may be appropriate to your own research question(s) and objectives.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Literature review</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#content-of-critical-review",
    "href": "chapter_3.html#content-of-critical-review",
    "title": "3  Literature review",
    "section": "3.3 Content of critical review",
    "text": "3.3 Content of critical review\nIn considering the content of the critical review, the researcher will therefore need:\n\nto include the key academic theories within your chosen area of research;\nto demonstrate that your knowledge of your chosen area is up to date;\nthrough clear referencing, enable those reading your project report to find the original publications which you cite.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Literature review</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#literature-sources",
    "href": "chapter_3.html#literature-sources",
    "title": "3  Literature review",
    "section": "3.4 Literature sources",
    "text": "3.4 Literature sources\n\n3.4.1 Steps in Literature review\n[![Literature review process. Source: Riedly\n(2018)](Images/lit_review_process.png)](https://www.amazon.co.uk/Literature-Review-Step-step-Students/dp/1412934265)\n\n\n3.4.2 Summarizing findings\nWe can start collecting and summarizing the literature in excel spreadsheets.\n\n\n\nExample: Summarized literature. Source: Charmarbagwala (2004)\n\n\nSummary findings can be organized in the spreadsheet too.\n\n\n\nExample: Summarized literature. Source: Charmarbagwala (2004)\n\n\nAnother approach could be using mindmap like softwares.\n\n\n\n3.4.3 Develop a critical approach\nIt is very common to see students writing literature review describing only one side of the story. There are few possibilities in scientific research works on a certain phenomena.\n\nThe phenomenon is known deterministically. There is no need for a second opinion. Example: what is the height of the Eifle Tower.\nThe phenomenon is known through estimations.\n\nExample 1: Let’s assume we want to review the research findings on the average female height in Germany. One cannot have a single answer for this because of\n\ndifferent sample size\ndifferent sampling techniques\ndifferent measurement methods/methodology\nmeasurement errors\ndifference in operational definitions etc.\n\nExample 2: Let’s assume we want to know the factors behind a successful job application. We cannot have a single line answer to this question too because of,\n\ndifferent sample size and sampling strategy\ndifferent hypotheses/variables taken into consideration\ndifferent sample characteristics\ndifference in operation definitions etc.\n\n\n\n3.4.4 Beware of confirmation bias\n\nConfirmation bias is the tendency to search for, interpret, favor, and recall information in a way that confirms or supports one’s prior beliefs or values. People display this bias when they select information that supports their views, ignoring contrary information, or when they interpret ambiguous evidence as supporting their existing attitudes. The effect is strongest for desired outcomes, for emotionally charged issues, and for deeply entrenched beliefs. Confirmation bias cannot be eliminated entirely, but it can be managed, for example, by education and training in critical thinking skills. Source: Wikipedia\n\nIt is not OK to cite only the side of the story that is in line with the authors findings.\n\n\n3.4.5 A big list of cognitive biases\nConfirmation bias is a type of cognitive bias. In addition, there are plenty of biases one may fall victim of, in conscious or in unconscious mind. To go through a helpful list of biases, the reader may right click on the following image and open it into a new window.\n\n\n\nCognitive biases. Source: Wikimedia. Right click and open it in a different window for better visibility.\n\n\n\n\n3.4.6 Gettier problem\nKnowledge is the justified true belief. It can be formulated as this,\nS knows that P, iff\n\nP is true\nS believes that P, and\nS is justified in believing that P.\n\nGettier argued that that there are cases where individuals can have a justified, true belief regarding a claim but still fail to know it because the reasons for the belief, while justified, turn out to be false.\nhttps://plato.stanford.edu/entries/knowledge-analysis/#GettProb\n\n\n\nError types. Source: XKCD\n\n\n\n\n\n\nSaunders, M. N. K., Philip Lewis, and Adrian Thornhill. 2019. Research Methods for Business Students. Eighth Edition. New York: Pearson.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Literature review</span>"
    ]
  },
  {
    "objectID": "chapter_4.html",
    "href": "chapter_4.html",
    "title": "4  Theoretical framework and hypothesis development",
    "section": "",
    "text": "4.1 Generating theory\nA good theoretical framework identifies and defines the important variables in the situation that are relevant to the problem and subsequently describes and explains the interconnections among these variables. The relationships between the independent variables, the dependent variable(s), are elaborated.\nIt is not always easy to come up with generally agreed‐upon definitions of the relevant variables. More often than not, there are many definitions available in the literature (for instance, there are literally dozens of definitions of “brand image,” “customer satisfaction,” and “service quality” available in the marketing literature). Still, well‐chosen guiding definitions of concepts are needed, because they will help you to provide an explanation for the relationships between the variables in your model. What’s more, they will also serve as a basis for the operationalization or measurement of your concepts in the data collection stage of the research process.\nHence, you will have to choose a useful definition from the literature (do not use dictionary definitions, they are usually too general). It is also important that you explain why you have chosen a particular definition as your guiding definition.\nA conceptual model helps you to structure your discussion of the literature. A conceptual model describes your ideas about how the concepts (variables) in your model are related to each other. A schematic diagram of the conceptual model helps the reader to visualize the theorized relationships between the variables in your model and thus to obtain a quick idea about how you think that the management problem can be solved. Hence, conceptual models are often expressed in this form. However, relationships between variables can also be ade- quately expressed in words. Both a schematic diagram of the conceptual model and a description of the relation- ships between the variables in words should be given, so that the reader can see and easily comprehend the theorized relationships. This facilitates and stimulates discussion about the relationships between the variables in your model. It is therefore important that your model is based on a sound theory.\nA theory or a clear explanation for the relationships in your model is the last component of the theoretical framework. A theory attempts to explain relationships between the variables in your model: an explanation should be provided for all the important relationships that are theorized to exist among the variables. If the nature and direction of the relationships can be theorized on the basis of the findings of previous research and/ or your own ideas on the subject, then there should also be an indication as to whether the relationships should be positive or negative and linear or nonlinear. From the theoretical framework, then, testable hypotheses can be developed to examine whether the theory formulated is valid or not.\nNote that you do not necessarily have to “invent” a new theory every time you are undertaking a research project. In an applied research context you apply existing theories to a specific context. This means that argu- ments can be drawn from previous research. However, in a basic research context you will make some contribution to existing theories and models. In such a case, it is not (always) possible to use existing theories or explanations for relationships between variables. As a result, you will have to rely on your own insights and ideas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Theoretical framework and hypothesis development</span>"
    ]
  },
  {
    "objectID": "chapter_4.html#generating-theory",
    "href": "chapter_4.html#generating-theory",
    "title": "4  Theoretical framework and hypothesis development",
    "section": "4.1 Generating theory",
    "text": "4.1 Generating theory\nA good theoretical framework identifies and defines the important variables in the situation that are relevant to the problem and subsequently describes and explains the interconnections among these variables. The relationships between the independent variables, the dependent variable(s), are elaborated.\nIt is not always easy to come up with generally agreed‐upon definitions of the relevant variables. More often than not, there are many definitions available in the literature (for instance, there are literally dozens of definitions of “brand image,” “customer satisfaction,” and “service quality” available in the marketing literature). Still, well‐chosen guiding definitions of concepts are needed, because they will help you to provide an explanation for the relationships between the variables in your model. What’s more, they will also serve as a basis for the operationalization or measurement of your concepts in the data collection stage of the research process.\nHence, you will have to choose a useful definition from the literature (do not use dictionary definitions, they are usually too general). It is also important that you explain why you have chosen a particular definition as your guiding definition.\nA conceptual model helps you to structure your discussion of the literature. A conceptual model describes your ideas about how the concepts (variables) in your model are related to each other. A schematic diagram of the conceptual model helps the reader to visualize the theorized relationships between the variables in your model and thus to obtain a quick idea about how you think that the management problem can be solved. Hence, conceptual models are often expressed in this form. However, relationships between variables can also be ade- quately expressed in words. Both a schematic diagram of the conceptual model and a description of the relation- ships between the variables in words should be given, so that the reader can see and easily comprehend the theorized relationships. This facilitates and stimulates discussion about the relationships between the variables in your model. It is therefore important that your model is based on a sound theory.\nA theory or a clear explanation for the relationships in your model is the last component of the theoretical framework. A theory attempts to explain relationships between the variables in your model: an explanation should be provided for all the important relationships that are theorized to exist among the variables. If the nature and direction of the relationships can be theorized on the basis of the findings of previous research and/ or your own ideas on the subject, then there should also be an indication as to whether the relationships should be positive or negative and linear or nonlinear. From the theoretical framework, then, testable hypotheses can be developed to examine whether the theory formulated is valid or not.\nNote that you do not necessarily have to “invent” a new theory every time you are undertaking a research project. In an applied research context you apply existing theories to a specific context. This means that argu- ments can be drawn from previous research. However, in a basic research context you will make some contribution to existing theories and models. In such a case, it is not (always) possible to use existing theories or explanations for relationships between variables. As a result, you will have to rely on your own insights and ideas."
  },
  {
    "objectID": "chapter_4.html#hypthothesis-development",
    "href": "chapter_4.html#hypthothesis-development",
    "title": "4  Theoretical framework and hypothesis development",
    "section": "4.2 Hypthothesis development",
    "text": "4.2 Hypthothesis development\n\n4.2.1 Definition of a hypothesis\nA hypothesis can be defined as a tentative, yet testable, statement, which predicts what you expect to find in your empirical data. Hypotheses are derived from the theory on which your conceptual model is based and are often relational in nature. Along these lines, hypotheses can be defined as logically conjectured relationships between two or more variables expressed in the form of testable statements. By testing the hypotheses and confirming the conjectured relationships, it is expected that solutions can be found to correct the problem encountered.\n\n4.2.1.1 If–then statements\nAs already stated, a hypothesis can be defined as a testable statement of the relationship among variables. A hypothesis can also test whether there are differences between two groups (or among several groups) with respect to any variable or variables. To examine whether or not the conjectured relationships or differences exist, these hypotheses can be set either as propositions or in the form of if–then statements. The two formats can be seen in the following two examples.\n\nYoung women will be more likely to express dissatisfaction with their body weight, when they are more frequently exposed to images of thin models in advertisements.\nIf young women are more frequently exposed to images of thin models in advertisements, then they will be more likely to express dissatisfaction with their body weight.\n\n\n\n4.2.1.2 Directional and nondirectional hypotheses\nIf, in stating the relationship between two variables or comparing two groups, terms such as positive, negative, more than, less than, and the like are used, then these are directional hypotheses because the direction of the relationship between the variables (positive/negative) is indicated, as in the first example below, or the nature of the difference between two groups on a variable (more than/less than) is postulated, as in the second example.\n\nThe greater the stress experienced in the job, the lower the job satisfaction of employees.\nWomen are more motivated than men.\n\nOn the other hand, nondirectional hypotheses are those that do postulate a relationship or difference, but offer no indication of the direction of these relationships or differences. In other words, though it may be conjectured that there is a significant relationship between two variables, we may not be able to say whether the relationship is positive or negative, as in the first example below. Likewise, even if we can conjecture that there will be differences between two groups on a particular variable, we may not be able to say which group will be more and which less on that variable, as in the second example.\nThere is a relation between arousal‐seeking tendency and consumer preferences for complex product designs. There is a difference between the work ethic values of American and Asian employees.\nNondirectional hypotheses are formulated either because the relationships or differences have never been explored, and hence there is no basis for indicating the direction, or because there have been conflicting findings in previous research studies on the variables. In some studies a positive relationship might have been found, while in others a negative relationship might have been traced. Hence, the current researcher might only be able to hypothesize that there is a significant relationship, but the direction may not be clear. In such cases, the hypotheses can be stated nondirectionally. Note that in the first example there is no clue as to whether arousal‐seeking tendency and preferences for complex product designs are positively or negatively correlated, and in the second example we do not know whether the work ethic values are stronger in Americans or in Asians. However, it would have been possible to state that arousal-seeking tendency and preferences for complex product designs are positively correlated, since previous research has indicated such a relationship. ‚",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Theoretical framework and hypothesis development</span>"
    ]
  },
  {
    "objectID": "chapter_5.html",
    "href": "chapter_5.html",
    "title": "5  Questionnaire Design",
    "section": "",
    "text": "5.1 Designing a questionnaire\nDesigning the questionnaire is the most important stage in this type of research because once the questionnaire is designed you have determined the questions and the answers and you will not be able to go back and get further information. You need to be sure that the questions you ask are going to enable you to gather the data that you need – here you need to refer back to your operational definitions. How do you ask a set of questions that will show you whether a person is happy or not? Or has had a ‘good’ holiday? Or even whether they have really eaten what they said they have eaten?\nDesigning a questionnaire is both about working out how you are going to measure the presence of something and about the practicalities of finding a set of questions and answers that will enable you to do that and be meaningful to and answerable by all your respondents.\nThinking about your research topic and designing a questionnaire to gather data:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Questionnaire Design</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#designing-a-questionnaire",
    "href": "chapter_5.html#designing-a-questionnaire",
    "title": "5  Questionnaire Design",
    "section": "",
    "text": "What do you want to know?\nWho will be able to answer the questions?\nWill they understand the questions?\nHow will they answer the questions?\nWill they be able to give the answers they want to give?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Questionnaire Design</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#different-types-of-data",
    "href": "chapter_5.html#different-types-of-data",
    "title": "5  Questionnaire Design",
    "section": "5.2 Different types of data",
    "text": "5.2 Different types of data\nA questionnaire is usually designed to collect a number of different types of data including:\n\nfacts – about people or events;\ndescriptions – people’s descriptions about something that, for example, has happened to them;\nknowledge – what people know about something;\nopinions – what their opinion is about something they have experienced or know about;\nattitudes/values – their attitudes towards other people, institutions, ideas and so on;\nbackground information about the respondent which may be linked to the research topic.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Questionnaire Design</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#different-types-of-answer",
    "href": "chapter_5.html#different-types-of-answer",
    "title": "5  Questionnaire Design",
    "section": "5.3 Different types of answer",
    "text": "5.3 Different types of answer\nQuestionnaires include ways of answering questions as well as ways of asking them. The two are clearly linked – the way the question is asked will determine the range of answers the respondent has to choose from. While this may seem obvious, it may not be immediately apparent that when designing the questionnaire you need to have the data you will gather in mind as well as the questions you have to ask to get that data. The nature of the data you gather will determine how you are able to work with it when you come to analyse it. These are the main types of answer – or data – you will get from a questionnaire:\n\nquantity – number of times, number of brothers, etc.;\ncategory – age category, e.g. 16–25 years; job category, e.g. manual worker;\nanswers chosen from a list of possible answers, e.g. yes/no/don’t know;\nposition on a scale – for example, from ‘very satisfied’ to ‘very unsatisfied’;\nrank position – for example, your first choice, your second choice, etc.;\nopen data – answers in respondents’ own words.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Questionnaire Design</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#types-of-question",
    "href": "chapter_5.html#types-of-question",
    "title": "5  Questionnaire Design",
    "section": "5.4 Types of question",
    "text": "5.4 Types of question\nThere are different ways of asking almost any question. The following are just some of the most commonly used questions in questionnaires.\n\n5.4.1 Yes/No\nThe most simple question asks for a ‘yes’ or ‘no’ response and is used as a way of distinguishing between different groups of respondents. Basically there is no point in asking a yes/no question if all your respondents are likely to answer one or the other unless you are using it as a check question to ensure that you have the respondents you want. All of your respondents should be able to answer ‘yes’ or ‘no’ but it is sometimes advisable to add a ‘don’t know’ or ‘not applicable’ category for any respondents who are unable to answer the question. In the example below it could be that the respondent has not been at home for the last six months because she has been in hospital.\n\n\n5.4.2 Which category? How many? How much?\nYou will probably want to ask questions about the respondents themselves or about a situation. This (usually) factual data needs to be collected in a way that makes it easy for the respondent to give the data accurately.\n\n\n5.4.3 Select from a list: single/multiple choice\nIf there are a set of answers we want respondents to choose from, it is common to list them and ask them either to select one or more or to ‘tick all that apply’. Think carefully about what information you want from the question. An ‘other’ category is often included so that respondents can add any other answers which they feel do not fit in the categories you have given them to choose from as in the first example below. In the second example this would not be appropriate.\n\n\n5.4.4 Agree/disagree with a statement: Likert scale\nIf you want to gather data about people’s ideas, values, opinions or attitudes, you can ask respondents whether they agree or disagree with a statement which you have devised.\n\n\n5.4.5 Rating scale\nAnother way of asking about respondents’ opinions or attitudes is to use a rating scale. In this case they are asked to place their answer on a scale which can be from 1 to 5, to 7, or to 9. It is usual to have an odd-numbered scale as this gives respondents the option of choosing the midpoints.\n\n\n5.4.6 Open question\nSometimes a questionnaire includes questions that allow respondents to answer as they wish. If the questionnaire is self-completion, a box is included for the respondent’s answer and the size of the box is usually an indication to the respondent of the length and detail of their expected answer.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Questionnaire Design</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#types-of-questionnaire",
    "href": "chapter_5.html#types-of-questionnaire",
    "title": "5  Questionnaire Design",
    "section": "5.5 Types of questionnaire",
    "text": "5.5 Types of questionnaire\n\n5.5.1 Personally administered questionnaires\nWhen the survey is confined to a local area a good way to collect data is to personally administer the questionnaires. The main advantage of this is that the researcher or a member of the research team can collect all the completed responses within a short period of time. Any doubts that the respondents might have on any question can be clarified on the spot. The researcher also has the opportunity to introduce the research topic and motivate the respondents to offer their frank answers.\nAdministering questionnaires to large numbers of individuals at the same time is less expensive and consumes less time than interviewing; equally, it does not require as much skill to administer a questionnaire as it does to conduct interviews. Wherever possible, questionnaires are best administered personally because of these advantages. A disadvantage of personally administered questionnaires is that the researcher may introduce a bias by explaining questions differently to different people; participants may be in fact answering different questions as compared to those to whom the questionnaire was mailed. What’s more, personally administered questionnaires take time and a lot of effort. For this reason, electronic questionnaires are widely used these days.\n\n\n5.5.2 Mail questionnaires\nA mail questionnaire is a self‐administered (paper and pencil) questionnaire that is sent to respondents via the mail. This method has long been the backbone of business research, but with the arrival of the Internet, mobile phones, and social networks, mail questionnaires have become redundant or even obsolete. Instead, online questionnaires are posted on the Internet or sent via email.\n\n\n\nAdvantages and disadvantages of different questionnaire\n\n\n\n\n5.5.3 Electronic and online questionnaires\nThe distribution of electronic or online questionnaires is easy and fast. All you have to do is to email the invitations to complete a survey, post a link on a website or personal blog, or use social networks. Online questionnaires are usually created as “web forms” with a database to store the answers and statistical software to provide statistical analysis. Until recently, conducting online surveys was a time‐consuming and tedious task requiring familiarity with web authoring programs, HTML codes, and/or scripting programs. Today, survey development software packages and online survey services make online survey research much easier and more accessible.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Questionnaire Design</span>"
    ]
  },
  {
    "objectID": "chapter_5.html#guidelines-for-questionnaire-design",
    "href": "chapter_5.html#guidelines-for-questionnaire-design",
    "title": "5  Questionnaire Design",
    "section": "5.6 Guidelines for questionnaire design",
    "text": "5.6 Guidelines for questionnaire design\nSound questionnaire design principles should focus on three areas. The first relates to the wording of the questions. The second refers to the planning of issues with regard to how the variables will be categorized, scaled, and coded after receipt of the responses. The third pertains to the general appearance of the questionnaire. All three are important issues in questionnaire design because they can minimize bias in research. These issues are discussed below.\n\n\n5.6.1 Reliability and Validity of Measurement\nReliability refers to the consistency of a measure. Psychologists consider three types of consistency: over time (test-retest reliability), across items (internal consistency), and across different researchers (inter-rater reliability).\n\n5.6.1.1 Test-retest reliability\nWhen researchers measure a construct that they assume to be consistent across time, then the scores they obtain should also be consistent across time. Test-retest reliabiliy is the extent to which this is actually the case. For example, intelligence is generally thought to be consistent across time. A person who is highly intelligent today will be highly intelligent next week. This means that any good measure of intelligence should produce roughly the same scores for this individual next week as it does today. Clearly, a measure that produces highly inconsistent scores over time cannot be a very good measure of a construct that is supposed to be consistent.\nAssessing test-retest reliability requires using the measure on a group of people at one time, using it again on the same group of people at a later time, and then looking at between the two sets of scores. This is typically done by graphing the data in a scatterplot and computing Pearson’s r. A high correlation implies reliability.\nAgain, high test-retest correlations make sense when the construct being measured is assumed to be consistent over time, which is the case for intelligence, self-esteem, and the Big Five personality dimensions. But other constructs are not assumed to be stable over time. The very nature of mood, for example, is that it changes. So a measure of mood that produced a low test-retest correlation over a period of a month would not be a cause for concern.\n\n\n5.6.1.2 Internal reliability\nA second kind of reliability is internal consistency, which is the consistency of people’s responses across the items on a multiple-item measure. In general, all the items on such measures are supposed to reflect the same underlying construct, so people’s scores on those items should be correlated with each other. On the Rosenberg Self-Esteem Scale, people who agree that they are a person of worth should tend to agree that that they have a number of good qualities. If people’s responses to the different items are not correlated with each other, then it would no longer make sense to claim that they are all measuring the same underlying construct. This is as true for behavioural and physiological measures as for self-report measures. For example, people might make a series of bets in a simulated game of roulette as a measure of their level of risk seeking. This measure would be internally consistent to the extent that individual participants’ bets were consistently high or low across trials.\nLike test-retest reliability, internal consistency can only be assessed by collecting and analyzing data. One approach is to look at a split-half correlation. This involves splitting the items into two sets, such as the first and second halves of the items or the even- and odd-numbered items. Then a score is computed for each set of items, and the relationship between the two sets of scores is examined. A split-half correlation of .80 or greater is generally considered good internal consistency.\nPerhaps the most common measure of internal consistency used by researchers in psychology is a statistic called Cronbach’s alpha. Conceptually, alpha is the mean of all possible split-half correlations for a set of items. For example, there are 252 ways to split a set of 10 items into two sets of five. Cronbach’s alpha would be the mean of the 252 split-half correlations. Note that this is not how alpha is actually computed, but it is a correct way of interpreting the meaning of this statistic. Again, a value of .80 or greater is generally taken to indicate good internal consistency.\n\n\n5.6.1.3 Interrater Reliability\nMany behavioural measures involve significant judgment on the part of an observer or a rater. Inter-rater reliability is the extent to which different observers are consistent in their judgments. For example, if you were interested in measuring university students’ social skills, you could make video recordings of them as they interacted with another student whom they are meeting for the first time. Then you could have two or more observers watch the videos and rate each student’s level of social skills. To the extent that each participant does in fact have some level of social skills that can be detected by an attentive observer, different observers’ ratings should be highly correlated with each other.\nInterrater reliability is often assessed using Cronbach’s alpha when the judgments are quantitative or an analogous statistic called Cohen’s kappa when they are categorical.\n\n\n\n5.6.2 Validity\nValidity is the extent to which the scores from a measure represent the variable they are intended to. But how do researchers make this judgment? We have already considered one factor that they take into account-reliability. When a measure has good test-retest reliability and internal consistency, researchers should be more confident that the scores represent what they are supposed to. There has to be more to it, however, because a measure can be extremely reliable but have no validity whatsoever. As an absurd example, imagine someone who believes that people’s index finger length reflects their self-esteem and therefore tries to measure self-esteem by holding a ruler up to people’s index fingers. Although this measure would have extremely good test-retest reliability, it would have absolutely no validity. The fact that one person’s index finger is a centimetre longer than another’s would indicate nothing about which one had higher self-esteem.\n\n\n5.6.3 Principles of wording\nThe principles of wording refer to such factors as:\n\nThe appropriateness of the content of the questions.\nHow questions are worded and the level of sophistication of the language used.\nThe type and form of questions asked.\nThe sequencing of the questions.\nThe personal data sought from the respondents. Each of these is explained below.\n\n\n5.6.3.1 Content and purpose of the questions\nThe nature of the variable tapped – subjective feelings or objective facts – will determine what kinds of questions are asked. If the variables tapped are of a subjective nature (e.g., satisfaction, involvement), where respondents’ beliefs, perceptions, and attitudes are to be measured, the questions should tap the dimensions and elements of the concept. Where objective variables, such as age and educational levels of respondents, are tapped, a single direct question – preferably one that has an ordinal scaled set of categories – is appropriate. Thus, the purpose of each question should be carefully considered so that the variables are adequately measured and yet no superfluous questions are asked.\n\n\n5.6.3.2 Language and wording of the questionnaire\nThe language of the questionnaire should approximate the level of understanding of the respondents. The choice of words will depend on their educational level, the usage of terms and idioms in the culture, and the frames of reference of the respondents. For instance, even when English is the spoken or official language in two cultures, certain words may be alien to one culture. Terms such as “working here is a drag” and “she is a compulsive worker” may not be interpreted the same way in different cultures. Some blue‐collar workers may not understand terminology such as “organizational structure.” Thus, it is essential to word the questions in a way that can be understood by the respondent. If some questions are either not understood or are interpreted differently by the respondent, the researcher will obtain the wrong answers to the questions, and responses will thus be biased. Hence, the questions asked, the language used, and the wording should be appropriate to tap respondents’ attitudes, perceptions, and feelings.\n\n\n5.6.3.3 Type and form of questions\nThe type of question refers to whether the question is open‐ended or closed. The form of the question refers to whether it is positively or negatively worded.\n\nOpen-ended versus closed questions Open‐ended questions allow respondents to answer them in any way they choose. An example of an open‐ended question is asking the respondent to state five things that are interesting and challenging in the job.\n\nAnother example is asking what the respondents like about their supervisors or their work environment. A third example is to invite their comments on the investment portfolio of the firm.\nA closed question, in contrast, asks the respondents to make choices among a set of alternatives given by the researcher. For instance, instead of asking the respondent to state any five aspects of the job that she finds interesting and challenging, the researcher might list 10 or 15 aspects that might seem interesting or challenging in jobs and ask the respondents to rank the first five among these in the order of their preference. All items in a questionnaire using a nominal, ordinal, Likert, or ratio scale are considered closed.\nClosed questions help the respondents to make quick decisions to choose among the several alternatives before them. They also help the researcher to code the information easily for subsequent analysis. Care has to be taken to ensure that the alternatives are mutually exclusive and collectively exhaustive. If there are overlapping categories, or if all possible alternatives are not given (i.e., the categories are not exhaustive), the respondents might get confused and the advantage of their being enabled to make a quick decision is thus lost.\nSome respondents may find even well‐delineated categories in a closed question rather confining and might avail themselves of the opportunity to make additional comments. This is the reason why many questionnaires end with a final open‐ended question that invites respondents to comment on topics that might not have been covered fully or adequately. The responses to such open‐ended questions have to be edited and categorized for subsequent data analysis.\n\nPositively and negatively worded questions Instead of phrasing all questions positively, it is advisable to include some negatively worded questions as well, so the tendency in respondents to mechanically circle the points toward one end of the scale is minimized.\n\nFor example, let us say that a set of six questions is used to tap the variable “perceived success” on a five‐point scale, with 1 being “very low” and 5 being “very high” on the scale. A respondent who is not particularly interested in completing the questionnaire is more likely to stay involved and remain alert while answering the questions when positively and negatively worded questions are interspersed in it.\nA set of example to start with is as follows.\nA positively framed question can be:\n“Should protests of pandemic-related restrictions be allowed?”\nA negatively framed approach of the same question can be,\n“Should protests of pandemic-related restrictions be forbidden?”\nFor instance, if the respondent has circled 5 for a positively worded question such as,\n“I feel I have been able to accomplish a number of different things in my job,”\nhe cannot circle number 5 again to the negatively worded question,\n“I do not feel I am very effective in my job.”\nThe respondent is now shaken out of any likely tendency to mechanically respond to one end of the scale. In case this does still happen, the researcher has an opportunity to detect such bias. A good questionnaire should therefore include both positively and negatively worded questions.\nThe use of double negatives and excessive use of the words “not” and “only” should be avoided in negatively worded questions because they tend to confuse respondents. For instance, it is better to say\n“Coming to work is not great fun”\nthan to say\n“Not coming to work is greater fun than coming to work.”\nLikewise, it is better to say\n“The rich need no help”\nthan to say\n“Only the rich do not need help.”\n\nDouble-barreled questions A question that lends itself to different possible responses to its subparts is called a double‐barreled question. Such questions should be avoided and two or more separate questions asked instead.\n\nFor example, the question\n“Do you think there is a good market for the product and that it will sell well?”\ncould bring a “yes” response to the first part (i.e., there is a good market for the product) and a “no” response to the latter part (i.e., it will not sell well for various other reasons).\nIn this case, it would be better to ask two questions:\n\n“Do you think there is a good market for the product?”\n\nand\n\n“Do you think the product will sell well?”\n\nThe answers might be “yes” to both, “no” to both, “yes” to the first and “no” to the second, or “yes” to the second and “no” to the first. If we combined the two questions and asked a double‐barreled question, we would confuse the respondents and obtain ambiguous responses. Hence, double‐barreled questions should be eliminated.\nAnother example,\n“Do you agree or disagree that the government should be responsible for providing clean drinking water and high-speed internet to everyone?”\n\nAmbiguous questions: Even questions that are not double‐barreled might be ambiguously worded and the respondent may not be sure what exactly they mean. An example of such a question is\n\n“To what extent would you say you are happy?”\nRespondents might find it difficult to decide whether the question refers to their state of feelings in the workplace, or at home, or in general. Thus, responses to ambiguous questions have built‐in bias in as much as different respondents might interpret such items in the questionnaire differently.\nThe result is a mixed bag of ambiguous responses that do not accurately provide the correct answer to the question.\n\nRecall-dependent questions Some questions might require respondents to recall experiences from the past that are hazy in their memory. Answers to such questions might have bias.\n\nFor instance, if an employee who has had 30 years’ service in the organization is asked to state when he first started working in a particular department and for how long, he may not be able to give the correct answers and may be way off in his responses. A better source for obtaining that information would be the personnel records.\n\nLeading questions Questions should not be phrased in such a way that they lead the respondents to give the responses that the researcher would like them to give. An example of such a question is:\n\n“Don’t you think that in these days of escalating costs of living, employees should be given good pay rises?”\nBy asking a leading question, we are signaling and pressuring respondents to say “yes.”\nTagging the question to rising living costs makes it difficult for most respondents (unless they are the top bosses in charge of budget and finances) to say,\n“No; not unless their productivity increases too!”\nAnother way of asking the question about pay rises to elicit less biased responses would be:\n“To what extent do you agree that employees should be given higher pay rises?”\nIf respondents think that the employees do not deserve a higher pay rise at all, their response will be “Strongly Disagree”; if they think that respondents should definitely be given a high pay rise, they will respond to the “Strongly Agree” end of the scale, and the in‐between points will be chosen depending on the strength of their agreement or disagreement. In this case, the question is not framed in a suggestive manner as in the previous instance.\nAnother example of a leading question:\n“The average daily work commute in the US takes 54.2 minutes and costs $29 per day. Since 2020, working from home has saved many employees time and money. Do you favor flexible work-from-home policies even after it’s safe to return to offices?\nExperts agree that a well-balanced diet provides sufficient vitamins and minerals, and multivitamins and supplements are not necessary or effective. Do you agree or disagree that multivitamins are helpful for balanced nutrition?\n\nLoaded questions Another type of bias in questions occurs when they are phrased in an emotionally charged manner. An example of such a loaded question is asking employees:\n\n“To what extent do you think management is likely to be vindictive if the union decides to go on strike?”\nThe words “strike” and “vindictive” are emotionally charged terms, polarizing management and unions. Hence, asking a question such as the above would elicit strongly emotional and highly biased responses. If the purpose of the question is twofold – that is, to find (1) the extent to which employees are in favor of a strike and (2) the extent to which they fear adverse reactions if they do go on strike – then these are the two specific questions that need to be asked. It may turn out that the employees are not strongly in favor of a strike and they also do not believe that management would retaliate if they did go on strike!\n\nSocial desirability Questions should not be worded such that they elicit socially desirable responses. For instance, a question such as\n\n“Do you think that older people should be laid off?”\nwould elicit a response of “no,” mainly because society would frown on a person who said that elderly people should be fired even if they are capable of performing their jobs satisfactorily. Hence, irrespective of the true feelings of the respondent, a socially desirable answer would be provided. If the purpose of the question is to gauge the extent to which organizations are seen as obligated to retain those above 65 years of age, a differently worded question with less pressure toward social desirability would be:\n“There are advantages and disadvantages to retaining senior citizens in the workforce. To what extent do you think companies should continue to keep the elderly on their payroll?”\nSometimes certain items that tap social desirability are deliberately introduced at various points in the questionnaire and an index of each individual’s social desirability tendency is calculated therefrom. This index is then applied to all other responses given by the individual in order to adjust for social desirability bias.\n\nLength of questions Finally, simple, short questions are preferable to long ones. As a rule of thumb, a question or a statement in the questionnaire should not exceed 20 words, or exceed one full line in print.\n\n\n\n5.6.3.4 Sequencing of questions\nThe sequence of questions in the questionnaire should be such that the respondent is led from questions of a general nature to those that are more specific, and from questions that are relatively easy to answer to those that are progressively more difficult. This funnel approach, as it is called, facilitates the easy and smooth progress of the respondent through the items in the questionnaire. The progression from general to specific questions might mean that the respondent is first asked questions of a global nature that pertain to the issue, and then is asked more incisive questions regarding the specific topic. Easy questions might relate to issues that do not involve much thinking; the more difficult ones might call for more thought, judgment, and decision making in providing the answers.\nIn determining the sequence of questions, it is advisable not to place contiguously a positively worded and a negatively worded question tapping the same element or dimension of a concept. For instance, placing two questions such as the following, one immediately after the other, is not only awkward but might also seem insulting to the respondent.\nI have opportunities to interact with my colleagues during work hours.\nI have few opportunities to interact with my colleagues during work hours.\nFirst, there is no need to ask the very same question in both a positive and a negative way. Second, if for some reason this is deemed necessary (e.g., to check the consistency of the responses), the two questions should be placed in different parts of the questionnaire, as far apart as possible.\nThe way questions are sequenced can also introduce certain biases, frequently referred to as ordering effects. Though randomly placing the questions in the questionnaire reduces any systematic bias in the responses, it is very rarely done, because of subsequent confusion while categorizing, coding, and analyzing the responses.\nIn sum, the language and wording of the questionnaire focus on such issues as the type and form of questions asked (i.e., open‐ended and closed questions, and positively and negatively worded questions), as well as avoiding double‐barreled questions, ambiguous questions, leading questions, loaded questions, questions prone to tap socially desirable answers, and those involving distant recall. Questions should also not be unduly long. Using the funnel approach helps respondents to progress through the questionnaire with ease and comfort.\n\n\n5.6.3.5 Classification data or personal information\nClassification data, also known as personal information or demographic questions, elicit such information as age, educational level, marital status, and income. Unless absolutely necessary, it is best not to ask for the name of the respondent. If, however, the questionnaire has to be identified with the respondents for any reason, then the questionnaire can be numbered and connected by the researcher to the respondent’s name, in a separately maintained, private document. This procedure should be clearly explained to the respondent. The reason for using the numerical system in questionnaires is to ensure the anonymity of the respondent.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Questionnaire Design</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Adams, John, Hafiz T. A. Khan, and R. Raeside. 2014. Research\nMethods for Business and Social Science Students. Second edition.\nLos Angeles: SAGE.\n\n\nBougie, Roger, and Uma Sekaran. 2020. Research Methods for Business:\nA Skill-Building Approach. Eight edition. Hoboken, NJ: Wiley.\n\n\nClough, Peter, and Cathy Nutbrown. 2012. A Student’s Guide to\nMethodology: Justifying Enquiry. 3rd ed. London: SAGE.\n\n\nGhauri, Pervez N., and Kjell Grønhaug. 2002. Research Methods in\nBusiness Studies: A Practical Guide. 2nd ed. Harlow, England ; New\nYork: Financial Times Prentice Hall.\n\n\nMcNiff, Jean, and Jack Whitehead. 2000. Action Research in\nOrganisations. Routledge Studies in Human Resource Development.\nLondon ; New York: Routledge.\n\n\nRobson, Colin, and Kieran McCartan. 2016. Real World Research: A\nResource for Users of Social Research Methods in Applied Settings.\nFourth Edition. Hoboken: Wiley.\n\n\nSaunders, M. N. K., Philip Lewis, and Adrian Thornhill. 2019.\nResearch Methods for Business Students. Eighth Edition. New\nYork: Pearson.\n\n\nWalliman, Nicholas. 2005. Your Research Project: A Step-by-Step\nGuide for the First-Time Researcher. 2nd ed. London ; Thousand\nOaks, Calif: Sage Publications."
  },
  {
    "objectID": "chapter_7.html",
    "href": "chapter_7.html",
    "title": "7  Measurement: Scaling, reliability and validity",
    "section": "",
    "text": "Measurement of the variables is an integral part of research and an important aspect of research design. Unless the variables are measured in some way, we will not be able to find answers to our research questions. Surveys and experimental designs often use questionnaires to measure the variables of interest."
  },
  {
    "objectID": "chapter_7.html#operational-definition-operationalisation",
    "href": "chapter_7.html#operational-definition-operationalisation",
    "title": "7  Measurement: Scaling, reliability and validity",
    "section": "7.2 Operational definition (operationalisation)",
    "text": "7.2 Operational definition (operationalisation)\nDespite the lack of physical measuring devices to measure the more nebulous variables, there are ways of tapping these types of variable. One technique is to reduce these abstract notions or concepts to observable behavior and/or characteristics. In other words, the abstract notions are broken down into observable behavior or characteristics. For instance, the concept of thirst is abstract; we cannot see it. However, we would expect a thirsty person to drink plenty of fluids. In other words, the expected reaction of people to thirst is to drink fluids. If several people say they are thirsty, then we may determine the thirst levels of each of these individuals by the measure of the quantity of fluids that they drink to quench their thirst. We will thus be able to measure their levels of thirst, even though the concept of thirst itself is abstract and nebulous. Reduction of abstract concepts to render them measurable in a tangible way is called operationalizing the concepts."
  },
  {
    "objectID": "chapter_7.html#four-types-of-scales",
    "href": "chapter_7.html#four-types-of-scales",
    "title": "7  Measurement: Scaling, reliability and validity",
    "section": "7.3 Four types of scales",
    "text": "7.3 Four types of scales\nMeasurement means gathering data in the form of numbers. To be able to assign numbers to attributes of objects we need a scale. A scale is a tool or mechanism by which individuals are distinguished as to how they differ from one another on the variables of interest to our study. Scaling involves the creation of a continuum on which our objects are located.\nSuppose that we want to measure consumer attitudes toward soft drink consumption. After we have developed one or more scale items or questions, the next step in measurement is to decide on a scale that allows us to assign numbers to the attribute (attitude toward soft drink consumption) of our objects (consumers). This allows us to subsequently classify our objects (consumers) in terms of how unfavorable or favorable they are toward drinking a soft drink. One of the many options we have to classify consumers is a Likert scale. The Likert scale is a scale designed to examine how strongly respondents agree with a statement (such as “I enjoy having a soft drink”) on a five-point scale with the following anchors: 1 = Strongly Disagree, 2 = Disagree, 3 = Neither Agree Nor Disagree, 4 = Agree, 5 = Strongly Agree. Hence, the Likert scale allows us to distinguish consumers in terms of how they differ from one another in their attitude toward soft drinks, each respondent being assigned a number indicating a more or less unfavorable, neutral, or more or less favorable.\nThe million dollar question is: What is the meaning of the numbers 1, 2, 3, 4, and 5? Does the scale that we have used allow us for instance to rank our objects (2 is more than 1)? Does it allow us to compare differences between objects (in other words is the difference between 1 and 2 the same as the difference between 2 and 3? And does it allow us to calculate certain statistics such as a mean (or average) and a standard deviation? The answer is: it depends. It depends on the type of scale (that is, the basic scale type) that we have used.\nThere are four basic types of scales: nominal, ordinal, interval, and ratio. The degree of sophistication to which the scales are fine-tuned increases progressively as we move from the nominal to the ratio scale. That is why information on the variables can be obtained in greater detail when we employ an interval or a ratio scale rather than using the other two scales. As the calibration or fine-tuning of the scale increases in sophistication, so does the power of the scale. With more powerful scales, increasingly sophisticated data analyses can be performed, which, in turn, means that more meaningful answers can be found to our research questions. However, certain variables lend themselves with greater ease to more powerful scaling than others. Let us now examine each of these four scales.\n\n7.3.1 Nominal scale\nA nominal scale is one that allows the researcher to assign subjects to certain categories or groups. For example, with respect to the variable of gender, respondents can be grouped into two categories – male and female. These two groups can be assigned code numbers 1 and 2. These numbers serve as simple and convenient category labels with no intrinsic value, other than to assign respondents to one of two non-overlapping, or mutually exclusive, categories. Note that the categories are also collectively exhaustive. In other words, there is no third category into which respondents would normally fall. Thus, nominal scales categorize individuals or objects into mutually exclusive and collectively exhaustive groups. The information that can be generated from nominal scaling is the calculation of the percentage (or frequency) of males and females in our sample of respondents. For example, if\nwe had interviewed 200 people, and assigned code number 1 to all male respondents and number 2 to all female respondents, then computer analysis of the data at the end of the survey may show that 98 of the respondents are men and 102 are women. This frequency distribution tells us that 49% of the survey’s respondents are men and 51% women. Other than this marginal information, such scaling tells us nothing more about the two groups. Thus, the nominal scale gives some basic, categorical, gross information.\n\n\n\nExample: nominal scaling\n\n\n\n\n7.3.2 Ordinal scale\nAn ordinal scale not only categorizes the variables in such a way as to denote differences among the various categories, it also rank-orders the categories in some meaningful way. With any variable for which the categories are to be ordered according to some preference, the ordinal scale would be used. The preference would be ranked (e.g., from best to worst; first to last) and numbered 1, 2, and so on. For example, respondents might be asked to indicate their preferences by ranking the importance they attach to five distinct characteristics in a job that the researcher might be interested in studying. Such a question might take the form shown in the following example.\nThe ordinal scale helps the researcher to determine the percentage of respondents who consider interaction with others as most important, those who consider using a number of different skills as most important, and so on. Such knowledge might help in designing jobs that are seen as most enriched by the majority of the employees.\nWe can now see that the ordinal scale provides more information than the nominal scale. The ordinal scale goes beyond differentiating the categories to providing information on how respondents distinguish them by rank-ordering them. Note, however, that the ordinal scale does not give any indication of the magnitude of the differences among the ranks. For instance, in the job characteristics example, the first-ranked job characteristic might be only marginally preferred over the second-ranked characteristic, whereas the characteristic that is ranked third might be preferred in a much larger degree than the one ranked fourth. Thus, in ordinal scaling, even though differences in the ranking of objects, persons, or events investigated are clearly known, we do not know their magnitude. This deficiency is overcome by interval scaling, which is discussed next.\n\n\n\nExample: ordinal scaling\n\n\n\n\n7.3.3 Interval scale\nIn an interval scale, or equal interval scale, numerically equal distances on the scale represent equal values in the characteristics being measured. Whereas the nominal scale allows us only to qualitatively distinguish groups by categorizing them into mutually exclusive and collectively exhaustive sets, and the ordinal scale to rank-order the preferences, the interval scale allows us to compare differences between objects. The difference between any two values on the scale is identical to the difference between any other two neighboring values of the scale. The clinical thermometer is a good example of an interval-scaled instrument; it has an arbitrary origin and the magnitude of the difference between 98.6 degrees (supposed to be the normal body temperature) and 99.6 degrees is the same as the magnitude of the difference between 104 and 105 degrees. Note, however, that one may not be seriously concerned if one’s temperature rises from 98.6 to 99.6, but one is likely to be so when the temperature goes up from 104 to 105 degrees!\nThe interval scale, then, taps the differences, the order, and the equality of the magnitude of the differences in the variable. As such, it is a more powerful scale than the nominal and ordinal scales, and has for its measure of cen- tral tendency the arithmetic mean. Its measures of dispersion are the range, the standard deviation, and the variance.\n\n\n7.3.4 Ratio scale\nThe ratio scale overcomes the disadvantage of the arbitrary origin point of the interval scale, in that it has an absolute (in contrast to an arbitrary) zero point, which is a meaningful measurement point. Thus, the ratio scale not only measures the magnitude of the differences between points on the scale but also taps the proportions in the differences. It is the most powerful of the four scales because it has a unique zero origin (not an arbitrary origin) and subsumes all the properties of the other three scales. The weighing balance is a good example of a ratio scale. It has an absolute (and not arbitrary) zero origin calibrated on it, which allows us to calculate the ratio of the weights of two individuals. For instance, a person weighing 250 pounds is twice as heavy as one who weighs 125 pounds. Note that multiplying or dividing both of these numbers (250 and 125) by any given number will preserve the ratio of 2:1. The measure of central tendency of the ratio scale may be either the arithmetic or the geometric mean and the measure of dispersion may be either the standard deviation, or variance, or the coefficient of variation. Some examples of ratio scales are those pertaining to actual age, income, and the number of organizations individuals have worked for.\n\n\n7.3.5 Examples and comparisons\n\n  ## Rating scales\nThe following rating scales are often used in business research: * Dichotomous scale * Category scale * Semantic differential scale * Numerical scale * Itemized rating scale * Likert scale * Fixed or constant sum rating scale * Stapel scale * Graphic rating scale * Consensus scale\nOther scales, such as the Thurstone Equal Appearing Interval Scale, and the multidimensional scale, are less frequently used. We will briefly describe each of the above attitudinal scales.\n\n\n7.3.6 Dichotomous scale\nThe dichotomous scale is used to elicit a Yes or No answer, as in the example below. Note that a nominal scale is used to elicit the response.\n\n\n\nExample: Dichotomous scale\n\n\n\n\n7.3.7 Category scale\nThe category scale uses multiple items to elicit a single response, as per the following example. This also uses the nominal scale.\n\n\n\nExample: Category scale\n\n\n\n\n7.3.8 Semantic differential scale\nSeveral bipolar attributes are identified at the extremes of the scale, and respondents are asked to indicate their attitudes, on what may be called a semantic space, toward a particular individual, object, or event on each of the attributes. The bipolar adjectives used might employ such terms as Good–Bad; Strong–Weak; Hot–Cold. The semantic differential scale is used to assess respondents’ attitudes toward a particular brand, advertisement, object, or individual. The responses can be plotted to obtain a good idea of their perceptions. A semantic differential scale is ordinal in nature. However, it is often treated as an interval scale. An example of the semantic differential scale follows.\n\n\n\nExample: Semantic differential scale scale\n\n\n\n\n7.3.9 Numerical scale\nThe numerical scale is similar to the semantic differential scale, with the difference that numbers on a five-point or seven-point scale are provided, with bipolar adjectives at both ends, as illustrated below. This scale is also often treated as an interval scale, although it is formally ordinal in nature.\n\n\n\nExample: Semantic differential scale scale\n\n\n\n\n7.3.10 Itemized rating scale\nA five-point or seven-point scale with anchors, as needed, is provided for each item and the respondent states the appropriate number on the side of each item, or circles the relevant number against each item, as per the examples that follow. The responses to the items are then summed. This uses an interval scale.\n\n\n\nExample: Itemized rating scale scale with a neutral point\n\n\nNote that, the above is a balanced rating scale with a neutral point.\n The itemized rating scale provides the flexibility to use as many points in the scale as considered necessary (4, 5, 7, 9, or whatever), and it is also possible to use different anchors (e.g., Very Unimportant to Very Important; Extremely Low to Extremely High). When a neutral point is provided, it is a balanced rating scale, and when it is not, it is an unbalanced rating scale.\nResearch indicates that a five-point scale is just as good as any, and that an increase from five to seven or nine points on a rating scale does not improve the reliability of the ratings (Elmore & Beggs, 1975).\n\n\n7.3.11 Likert scale\nThe Likert scale is designed to examine how strongly subjects agree or disagree with statements on a five-point scale with the following anchors:\n The responses over a number of items tapping a particular concept or variable can be analyzed item by item, but it is also possible to calculate a total or summated score for each respondent by summing across items. The summated approach is widely used, and therefore the Likert scale is also referred to as a summated scale.\nIn the following example, the scores on the second item have to be reversed before calculating the summated score, because a high score on this item reflects an unfavorable attitude to work, whereas a high score on items 1 and 3 reflects a favorable attitude to work. This will lead to high total scores for respondents who have a favorable attitude toward work and to low total scores for respondents who have an unfavorable attitude toward work.\n ### Fixed or constant sum scale\nThe respondents are here asked to distribute a given number of points across various items as per the example below. This is more in the nature of an ordinal scale.\n\n\n\nExample: Fixed or constant sum scale\n\n\n\n\n7.3.12 Stapel scale\nThis scale simultaneously measures both the direction and intensity of the attitude toward the items under study. The characteristic of interest to the study is placed at the center with a numerical scale ranging, say, from \\(+3\\) to \\(−3\\), on either side of the item, as illustrated in the example below. This gives an idea of how close or distant the individual response to the stimulus is. Since this does not have an absolute zero point, this is an interval scale.\n ### Graphic rating scale\nA graphical representation helps the respondents to indicate on this scale their answers to a particular question by placing a mark at the appropriate point on the line, as in the following example. This is an ordinal scale, though the following example might make it look like an interval scale.\n ### Consensus scale Scales can also be developed by consensus, where a panel of judges selects certain items, which in its view meas- ure the relevant concept. The items are chosen particularly based on their pertinence or relevance to the concept. Such a consensus scale is developed after the selected items have been examined and tested for their validity and reliability. One such consensus scale is the Thurstone Equal Appearing Interval Scale, where a concept is measured by a complex process followed by a panel of judges. Using a pile of cards containing several descriptions of the concept, a panel of judges offers inputs to indicate how close or not the statements are to the concept under study. The scale is then developed based on the consensus reached. However, this scale is rarely used for measuring organizational concepts because of the time necessary to develop it.\n\n\n7.3.13 Other scales\nThere are also some advanced scaling methods such as multidimensional scaling, where objects, people, or both, are visually scaled, and a conjoint analysis is performed. This provides a visual image of the relationships in space among the dimensions of a construct.\nIt should be noted that the Likert or some form of numerical scale is the one most frequently used to measure attitudes and behaviors in business research."
  },
  {
    "objectID": "chapter_7.html#goodness-of-measures",
    "href": "chapter_7.html#goodness-of-measures",
    "title": "7  Measurement: Scaling, reliability and validity",
    "section": "7.4 Goodness of measures",
    "text": "7.4 Goodness of measures\nNow that we have seen how to operationally define variables and apply different scaling techniques, it is important to make sure that the instrument that we develop to measure a particular concept is indeed accurately measuring the variable, and that, in fact, we are actually measuring the concept that we set out to measure. This ensures that in operationally defining perceptual and attitudinal variables, we have not overlooked some important dimensions and elements or included some irrelevant ones. The scales developed can often be imperfect, and errors are prone to occur in the measurement of attitudinal variables. The use of better instruments will ensure more accuracy in results, which in turn will enhance the scientific quality of the research. Hence, in some way, we need to assess the “goodness” of the measures developed. That is, we need to be reasonably sure that the instruments we use in our research do indeed measure the variables they are supposed to, and that they measure them accurately.\n ### Reliability\nThe reliability of a measure indicates the extent to which it is without bias (error free) and hence ensures consist- ent measurement across time and across the various items in the instrument. In other words, the reliability of a measure is an indication of the stability and consistency with which the instrument measures the concept and helps to assess the “goodness” of a measure.\n\n7.4.0.1 Stability of measures\nThe ability of a measure to remain the same over time - despite uncontrollable testing conditions or the state of the respondents themselves - is indicative of its stability and low vulnerability to changes in the situation. This attests to its “goodness” because the concept is stably measured, no matter when it is done. Two tests of stability are test–retest reliability and parallel-form reliability.\n\nTest–retest reliability: The reliability coefficient obtained by repetition of the same measure on a second occasion is called the test–retest reliability. That is, when a questionnaire containing some items that are sup- posed to measure a concept is administered to a set of respondents, now and again to the same respondents, say several weeks to six months later, then the correlation between the scores obtained at the two different times from one and the same set of respondents is called the test–retest coefficient. The higher it is, the better the test– retest reliability and, consequently, the stability of the measure across time.\nParallel-form reliability: When responses on two comparable sets of measures tapping the same construct are highly correlated, we have parallel-form reliability. Both forms have similar items and the same response format, the only changes being the wording and the order or sequence of the questions. What we try to establish here is the error variability resulting from wording and ordering of the questions. If two such comparable forms are highly correlated (say 8 and above), we may be fairly certain that the measures are reasonably reliable, with minimal error variance caused by wording, ordering, or other factors.\n\nInternal consistency of measures The internal consistency of measures is indicative of the homogeneity of the items in the measure that taps the construct. In other words, the items should “hang together as a set,” and be capable of independently measuring the same concept so that the respondents attach the same overall meaning to each of the items. This can be seen by examining whether the items and the subsets of items in the measuring instrument are correlated highly. Consistency can be examined through the inter-item consistency reliability and split-half reliability tests.\n\nInteritem consistency reliability: The interitem consistency reliability is a test of the consistency of respondents’ answers to all the items in a measure. To the degree that items are independent measures of the same concept, they will be correlated with one another. The most popular test of inter-item consistency reliability is Cronbach’s coefficient alpha (Cronbach, 1946), which is used for multipoint-scaled items, and the Kuder–Richardson formulas (Kuder & Richardson, 1937), used for dichotomous items. The higher the coefficients, the better the measuring instrument.\nSplit-half reliability: Split-half reliability reflects the correlations between two halves of an instrument. The estimates will vary depending on how the items in the measure are split into two halves. Split-half reliabilities may be higher than Cronbach’s alpha only in the circumstance of there being more than one underlying response dimension tapped by the measure and when certain other conditions are met as well (for complete details, refer to Campbell, 1976). Hence, in almost all cases, Cronbach’s alpha can be considered a perfectly adequate index of the inter-item consistency reliability."
  },
  {
    "objectID": "chapter_2.html#attributes-of-a-good-research-topic",
    "href": "chapter_2.html#attributes-of-a-good-research-topic",
    "title": "2  Formulating and clarifying the research topic",
    "section": "",
    "text": "Is the topic something with which you are really fascinated?\nDo you have, or can you develop within the project time frame, the necessary research skills to undertake the topic?\nIs the research topic achievable within the available time?\nWill the project still be current when you finish your project?\nIs the research topic achievable within the financial resources that are likely to be available?\nAre you reasonably certain of being able to gain access to data you are likely to require for this topic?\n\n\n\nDoes the topic fit the specifications and meet the standards set by the examining institution?\nDoes your research topic contain issues that have a clear link to theory?\nAre you able to state your research question(s) and objectives clearly?\nWill your proposed research be able to provide fresh insights into this topic?\nDoes your research topic relate clearly to the idea you have been given (perhaps by an organisation)?\nAre the findings for this research topic likely to be symmetrical: that is, of similar value whatever the outcome?\nDoes the research topic match your career goals?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Formulating and clarifying the research topic</span>"
    ]
  },
  {
    "objectID": "chapter_3.html#a-continous-process",
    "href": "chapter_3.html#a-continous-process",
    "title": "3  Literature review",
    "section": "3.1 A continous process",
    "text": "3.1 A continous process\nAfter setting up the research question and hypotheses, we need to see what others did in the same subject area. This process is called literature review. There are several objectives of literature review:\n\nTo see what methodologies are appropriate for the analysis\nTo understand the gaps in the field\nTo know the improvement suggestions from other researchers\n\nThe literature review can be started while setting up the research question and hypotheses and can continue till the end of the research project. This is because, the research process is often very long and it is important to get updated with publications during ongoing research project. Graphically, it may look like this,\n\n\n\nFigure 3.1: The literature review process (Saunders, Lewis, and Thornhill (2019))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Data Science",
    "section": "",
    "text": "Welcome note\nDear students,\nIn this part of this course, we are going to cover theoretical background for doing research work. In this part we are going to cover the following topics:\n\nWhat is research, formulating and clarifying the research topic\nLiterature review\nTheoretical framework and hypothesis development\nQuestionnaire design\nSampling design\nMeasurement: scaling, reliability and validity",
    "crumbs": [
      "Welcome note"
    ]
  },
  {
    "objectID": "chapter_3.html#a-continuous-process",
    "href": "chapter_3.html#a-continuous-process",
    "title": "3  Literature review",
    "section": "",
    "text": "To see what methodologies are appropriate for the analysis\nTo understand the gaps in the field\nTo know the improvement suggestions from other researchers\n\n\n\n\n\n\n\n\nFigure 3.1: The literature review process (Saunders, Lewis, and Thornhill (2019))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Literature review</span>"
    ]
  }
]